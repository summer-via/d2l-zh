{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2.3090, train acc 000, test acc 0.184\n",
      "epoch 1, loss 2.1995, train acc 000, test acc 0.445\n",
      "epoch 1, loss 2.1093, train acc 000, test acc 0.465\n",
      "epoch 1, loss 2.0404, train acc 000, test acc 0.375\n",
      "epoch 1, loss 1.9796, train acc 000, test acc 0.648\n",
      "epoch 1, loss 1.9138, train acc 000, test acc 0.562\n",
      "epoch 1, loss 1.8583, train acc 000, test acc 0.633\n",
      "epoch 1, loss 1.8072, train acc 000, test acc 0.629\n",
      "epoch 1, loss 1.7640, train acc 000, test acc 0.656\n",
      "epoch 1, loss 1.7292, train acc 000, test acc 0.586\n",
      "epoch 1, loss 1.6921, train acc 000, test acc 0.598\n",
      "epoch 1, loss 1.6694, train acc 000, test acc 0.617\n",
      "epoch 1, loss 1.6422, train acc 000, test acc 0.680\n",
      "epoch 1, loss 1.6123, train acc 000, test acc 0.652\n",
      "epoch 1, loss 1.5851, train acc 000, test acc 0.625\n",
      "epoch 1, loss 1.5616, train acc 000, test acc 0.629\n",
      "epoch 1, loss 1.5414, train acc 000, test acc 0.660\n",
      "epoch 1, loss 1.5161, train acc 000, test acc 0.656\n",
      "epoch 1, loss 1.4955, train acc 000, test acc 0.684\n",
      "epoch 1, loss 1.4741, train acc 000, test acc 0.656\n",
      "epoch 1, loss 1.4546, train acc 000, test acc 0.699\n",
      "epoch 1, loss 1.4378, train acc 000, test acc 0.656\n",
      "epoch 1, loss 1.4194, train acc 000, test acc 0.707\n",
      "epoch 1, loss 1.4066, train acc 000, test acc 0.695\n",
      "epoch 1, loss 1.3905, train acc 000, test acc 0.699\n",
      "epoch 1, loss 1.3758, train acc 000, test acc 0.699\n",
      "epoch 1, loss 1.3619, train acc 000, test acc 0.715\n",
      "epoch 1, loss 1.3500, train acc 000, test acc 0.656\n",
      "epoch 1, loss 1.3382, train acc 000, test acc 0.695\n",
      "epoch 1, loss 1.3276, train acc 000, test acc 0.707\n",
      "epoch 1, loss 1.3150, train acc 000, test acc 0.723\n",
      "epoch 1, loss 1.3042, train acc 000, test acc 0.699\n",
      "epoch 1, loss 1.2910, train acc 000, test acc 0.734\n",
      "epoch 1, loss 1.2828, train acc 000, test acc 0.703\n",
      "epoch 1, loss 1.2715, train acc 000, test acc 0.730\n",
      "epoch 1, loss 1.2625, train acc 000, test acc 0.727\n",
      "epoch 1, loss 1.2555, train acc 000, test acc 0.641\n",
      "epoch 1, loss 1.2471, train acc 000, test acc 0.707\n",
      "epoch 1, loss 1.2380, train acc 000, test acc 0.758\n",
      "epoch 1, loss 1.2292, train acc 000, test acc 0.715\n",
      "epoch 1, loss 1.2195, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.2107, train acc 000, test acc 0.711\n",
      "epoch 1, loss 1.2020, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.1943, train acc 000, test acc 0.707\n",
      "epoch 1, loss 1.1869, train acc 000, test acc 0.738\n",
      "epoch 1, loss 1.1796, train acc 000, test acc 0.738\n",
      "epoch 1, loss 1.1719, train acc 000, test acc 0.742\n",
      "epoch 1, loss 1.1665, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.1597, train acc 000, test acc 0.762\n",
      "epoch 1, loss 1.1549, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.1492, train acc 000, test acc 0.727\n",
      "epoch 1, loss 1.1429, train acc 000, test acc 0.758\n",
      "epoch 1, loss 1.1380, train acc 000, test acc 0.750\n",
      "epoch 1, loss 1.1334, train acc 000, test acc 0.750\n",
      "epoch 1, loss 1.1274, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.1209, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.1147, train acc 000, test acc 0.711\n",
      "epoch 1, loss 1.1103, train acc 000, test acc 0.750\n",
      "epoch 1, loss 1.1039, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.0985, train acc 000, test acc 0.762\n",
      "epoch 1, loss 1.0934, train acc 000, test acc 0.773\n",
      "epoch 1, loss 1.0873, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0832, train acc 000, test acc 0.711\n",
      "epoch 1, loss 1.0790, train acc 000, test acc 0.730\n",
      "epoch 1, loss 1.0739, train acc 000, test acc 0.758\n",
      "epoch 1, loss 1.0707, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0667, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0633, train acc 000, test acc 0.746\n",
      "epoch 1, loss 1.0594, train acc 000, test acc 0.766\n",
      "epoch 1, loss 1.0548, train acc 000, test acc 0.770\n",
      "epoch 1, loss 1.0509, train acc 000, test acc 0.770\n",
      "epoch 1, loss 1.0474, train acc 000, test acc 0.785\n",
      "epoch 1, loss 1.0430, train acc 000, test acc 0.758\n",
      "epoch 1, loss 1.0380, train acc 000, test acc 0.758\n",
      "epoch 1, loss 1.0340, train acc 000, test acc 0.770\n",
      "epoch 1, loss 1.0306, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0268, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0239, train acc 000, test acc 0.754\n",
      "epoch 1, loss 1.0210, train acc 000, test acc 0.738\n",
      "epoch 1, loss 1.0185, train acc 000, test acc 0.777\n",
      "epoch 1, loss 1.0154, train acc 000, test acc 0.766\n",
      "epoch 1, loss 1.0123, train acc 000, test acc 0.762\n",
      "epoch 1, loss 1.0088, train acc 000, test acc 0.766\n",
      "epoch 1, loss 1.0055, train acc 000, test acc 0.801\n",
      "epoch 1, loss 1.0015, train acc 000, test acc 0.781\n",
      "epoch 1, loss 0.9990, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.9964, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.9929, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9904, train acc 000, test acc 0.770\n",
      "epoch 1, loss 0.9877, train acc 000, test acc 0.734\n",
      "epoch 1, loss 0.9850, train acc 000, test acc 0.734\n",
      "epoch 1, loss 0.9829, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9809, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9785, train acc 000, test acc 0.777\n",
      "epoch 1, loss 0.9757, train acc 000, test acc 0.797\n",
      "epoch 1, loss 0.9726, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9698, train acc 000, test acc 0.773\n",
      "epoch 1, loss 0.9674, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9650, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9623, train acc 000, test acc 0.781\n",
      "epoch 1, loss 0.9594, train acc 000, test acc 0.777\n",
      "epoch 1, loss 0.9572, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9548, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9521, train acc 000, test acc 0.766\n",
      "epoch 1, loss 0.9497, train acc 000, test acc 0.777\n",
      "epoch 1, loss 0.9476, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9459, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9436, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.9413, train acc 000, test acc 0.781\n",
      "epoch 1, loss 0.9396, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9377, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.9355, train acc 000, test acc 0.793\n",
      "epoch 1, loss 0.9338, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9321, train acc 000, test acc 0.758\n",
      "epoch 1, loss 0.9300, train acc 000, test acc 0.770\n",
      "epoch 1, loss 0.9281, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9266, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9249, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9226, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.9197, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9178, train acc 000, test acc 0.754\n",
      "epoch 1, loss 0.9163, train acc 000, test acc 0.773\n",
      "epoch 1, loss 0.9145, train acc 000, test acc 0.746\n",
      "epoch 1, loss 0.9134, train acc 000, test acc 0.785\n",
      "epoch 1, loss 0.9111, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.9093, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9077, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9059, train acc 000, test acc 0.762\n",
      "epoch 1, loss 0.9048, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.9026, train acc 000, test acc 0.793\n",
      "epoch 1, loss 0.9012, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.9003, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8983, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8964, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.8948, train acc 000, test acc 0.781\n",
      "epoch 1, loss 0.8933, train acc 000, test acc 0.770\n",
      "epoch 1, loss 0.8920, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8906, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8890, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8870, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.8856, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8845, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8828, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8811, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.8792, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8782, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8765, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8748, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8730, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.8713, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8701, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8688, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8676, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8667, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8656, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8645, train acc 000, test acc 0.793\n",
      "epoch 1, loss 0.8634, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.8622, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.8618, train acc 000, test acc 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.8609, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8600, train acc 000, test acc 0.832\n",
      "epoch 1, loss 0.8586, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8570, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8556, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8546, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8535, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8518, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8507, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.8493, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8480, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8471, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8462, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8450, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8437, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8425, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8420, train acc 000, test acc 0.797\n",
      "epoch 1, loss 0.8409, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8392, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8385, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8376, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8361, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8346, train acc 000, test acc 0.836\n",
      "epoch 1, loss 0.8331, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8315, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8304, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8293, train acc 000, test acc 0.832\n",
      "epoch 1, loss 0.8283, train acc 000, test acc 0.789\n",
      "epoch 1, loss 0.8274, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8270, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8255, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8243, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8234, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8226, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8214, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8203, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8193, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8182, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8173, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8160, train acc 000, test acc 0.836\n",
      "epoch 1, loss 0.8152, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8144, train acc 000, test acc 0.832\n",
      "epoch 1, loss 0.8133, train acc 000, test acc 0.773\n",
      "epoch 1, loss 0.8127, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8116, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8111, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.8097, train acc 000, test acc 0.836\n",
      "epoch 1, loss 0.8088, train acc 000, test acc 0.832\n",
      "epoch 1, loss 0.8083, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8074, train acc 000, test acc 0.832\n",
      "epoch 1, loss 0.8069, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.8063, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8055, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.8047, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.8037, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.8027, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.8020, train acc 000, test acc 0.809\n",
      "epoch 1, loss 0.8013, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.8007, train acc 000, test acc 0.801\n",
      "epoch 1, loss 0.7998, train acc 000, test acc 0.805\n",
      "epoch 1, loss 0.7988, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.7983, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.7972, train acc 000, test acc 0.812\n",
      "epoch 1, loss 0.7965, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.7957, train acc 000, test acc 0.836\n",
      "epoch 1, loss 0.7949, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.7941, train acc 000, test acc 0.816\n",
      "epoch 1, loss 0.7936, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.7925, train acc 000, test acc 0.824\n",
      "epoch 1, loss 0.7918, train acc 000, test acc 0.797\n",
      "epoch 1, loss 0.7909, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.7901, train acc 000, test acc 0.828\n",
      "epoch 1, loss 0.7892, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.7881, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.7872, train acc 000, test acc 0.820\n",
      "epoch 1, loss 0.7867, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.6038, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.6082, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5831, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.6023, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5884, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5880, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5915, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5931, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.6089, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.6094, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.6004, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.6012, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5984, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5995, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5964, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5972, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5958, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5951, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5951, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5939, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5973, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5967, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5961, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5933, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5901, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5902, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5904, train acc 000, test acc 0.797\n",
      "epoch 2, loss 0.5903, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5916, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5933, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5925, train acc 000, test acc 0.797\n",
      "epoch 2, loss 0.5938, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5936, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5939, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5929, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5931, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5939, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5963, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5971, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5971, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5983, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5982, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5989, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5976, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5960, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5953, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5955, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5967, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5979, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5982, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5968, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5959, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5957, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5954, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5953, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5951, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5961, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5962, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5970, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5973, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5992, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5994, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5990, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5978, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5989, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5989, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5984, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5988, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5976, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5976, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5967, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5969, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5960, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5963, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5969, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5973, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5969, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5964, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5962, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5968, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5969, train acc 000, test acc 0.801\n",
      "epoch 2, loss 0.5985, train acc 000, test acc 0.797\n",
      "epoch 2, loss 0.5997, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5995, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5996, train acc 000, test acc 0.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.5995, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5991, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5985, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5973, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5962, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5962, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5952, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5945, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5942, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5946, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5943, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5940, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5937, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5934, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5933, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5935, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5935, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5935, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5932, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5930, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5931, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5925, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5926, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5933, train acc 000, test acc 0.781\n",
      "epoch 2, loss 0.5930, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5921, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5923, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5920, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5921, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5921, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5919, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5917, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5914, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5916, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5913, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5919, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5914, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5916, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5912, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5906, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5905, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5905, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5900, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5906, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5908, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5905, train acc 000, test acc 0.844\n",
      "epoch 2, loss 0.5900, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5894, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5889, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5890, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5889, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5887, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5888, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5889, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5889, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5886, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5879, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5874, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5869, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5870, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5868, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5864, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5861, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5855, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5851, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5852, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5851, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5854, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5854, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5855, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5858, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5858, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5856, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5854, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5852, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5847, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5844, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5839, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5842, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5841, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5842, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5840, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5836, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5833, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5832, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5831, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5829, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5828, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5821, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5819, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5814, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5813, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5807, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5807, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5807, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5810, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5810, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5808, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5805, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5799, train acc 000, test acc 0.848\n",
      "epoch 2, loss 0.5797, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5796, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5796, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5797, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5794, train acc 000, test acc 0.844\n",
      "epoch 2, loss 0.5795, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5795, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5794, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5790, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5786, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5784, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5785, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5788, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5787, train acc 000, test acc 0.805\n",
      "epoch 2, loss 0.5781, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5787, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5785, train acc 000, test acc 0.789\n",
      "epoch 2, loss 0.5785, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5782, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5782, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5781, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5784, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5787, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5783, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5783, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5782, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5777, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5777, train acc 000, test acc 0.812\n",
      "epoch 2, loss 0.5780, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5781, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5780, train acc 000, test acc 0.824\n",
      "epoch 2, loss 0.5778, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5777, train acc 000, test acc 0.836\n",
      "epoch 2, loss 0.5778, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5775, train acc 000, test acc 0.816\n",
      "epoch 2, loss 0.5773, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5773, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5775, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5774, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5774, train acc 000, test acc 0.820\n",
      "epoch 2, loss 0.5774, train acc 000, test acc 0.848\n",
      "epoch 2, loss 0.5769, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5764, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5762, train acc 000, test acc 0.809\n",
      "epoch 2, loss 0.5758, train acc 000, test acc 0.828\n",
      "epoch 2, loss 0.5754, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5754, train acc 000, test acc 0.832\n",
      "epoch 2, loss 0.5752, train acc 000, test acc 0.840\n",
      "epoch 2, loss 0.5751, train acc 000, test acc 0.844\n",
      "epoch 2, loss 0.5749, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.4932, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5233, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5851, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5795, train acc 000, test acc 0.812\n",
      "epoch 3, loss 0.5829, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5691, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5678, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5852, train acc 000, test acc 0.812\n",
      "epoch 3, loss 0.5736, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5746, train acc 000, test acc 0.844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.5709, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5721, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5753, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5747, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5682, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5660, train acc 000, test acc 0.816\n",
      "epoch 3, loss 0.5596, train acc 000, test acc 0.809\n",
      "epoch 3, loss 0.5601, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5524, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5540, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5541, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5523, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5478, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5505, train acc 000, test acc 0.848\n",
      "epoch 3, loss 0.5498, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5476, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5500, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5494, train acc 000, test acc 0.816\n",
      "epoch 3, loss 0.5491, train acc 000, test acc 0.816\n",
      "epoch 3, loss 0.5492, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5501, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5482, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5472, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5455, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5440, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5435, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5437, train acc 000, test acc 0.809\n",
      "epoch 3, loss 0.5438, train acc 000, test acc 0.809\n",
      "epoch 3, loss 0.5456, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5467, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5468, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5492, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5483, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5487, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5501, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5477, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5481, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5478, train acc 000, test acc 0.809\n",
      "epoch 3, loss 0.5490, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5487, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5485, train acc 000, test acc 0.812\n",
      "epoch 3, loss 0.5476, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5481, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5493, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5481, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5479, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5479, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5469, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5461, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5455, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5451, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5436, train acc 000, test acc 0.816\n",
      "epoch 3, loss 0.5436, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5436, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5432, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5429, train acc 000, test acc 0.805\n",
      "epoch 3, loss 0.5424, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5435, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5433, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5434, train acc 000, test acc 0.816\n",
      "epoch 3, loss 0.5437, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5442, train acc 000, test acc 0.844\n",
      "epoch 3, loss 0.5443, train acc 000, test acc 0.844\n",
      "epoch 3, loss 0.5429, train acc 000, test acc 0.848\n",
      "epoch 3, loss 0.5429, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5435, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5440, train acc 000, test acc 0.852\n",
      "epoch 3, loss 0.5441, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5441, train acc 000, test acc 0.805\n",
      "epoch 3, loss 0.5446, train acc 000, test acc 0.848\n",
      "epoch 3, loss 0.5437, train acc 000, test acc 0.820\n",
      "epoch 3, loss 0.5433, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5429, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5432, train acc 000, test acc 0.844\n",
      "epoch 3, loss 0.5430, train acc 000, test acc 0.836\n",
      "epoch 3, loss 0.5428, train acc 000, test acc 0.840\n",
      "epoch 3, loss 0.5420, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5419, train acc 000, test acc 0.848\n",
      "epoch 3, loss 0.5416, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5418, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5420, train acc 000, test acc 0.805\n",
      "epoch 3, loss 0.5421, train acc 000, test acc 0.832\n",
      "epoch 3, loss 0.5423, train acc 000, test acc 0.824\n",
      "epoch 3, loss 0.5431, train acc 000, test acc 0.828\n",
      "epoch 3, loss 0.5433, train acc 000, test acc 0.820\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import autograd, nd\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = nd.random.normal(scale=0.01, shape=(num_inputs, num_outputs))\n",
    "b = nd.zeros(num_outputs)\n",
    "\n",
    "W.attach_grad()\n",
    "b.attach_grad()\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(axis=1, keepdims=True)\n",
    "    return X_exp / partition\n",
    "\n",
    "X = nd.random.normal(shape=(2, 5))\n",
    "X_prob = softmax(X)\n",
    "# X_prob, X_prob.sum(axis=1)\n",
    "def net(X):\n",
    "    return softmax(nd.dot(X.reshape((-1, num_inputs)), W) + b)\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -nd.pick(y_hat, y).log()\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(axis=1) == y.astpyr('float32')).mean().asscalar()\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        y = y.astype('float32')\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum().asscalar()\n",
    "        n += y.size\n",
    "        return acc_sum / n\n",
    "\n",
    "# 训练模型\n",
    "num_epochs, lr = 5, 0.1\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, trainer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            if trainer is None:\n",
    "                d2l.sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3d, test acc %.3f' \n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "            \n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W,b], lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
